{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating datasets with PyTables via NumPy arrays is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/array1 (Array(20, 5)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tables as tb\n",
    "\n",
    "# Create a new file\n",
    "f = tb.open_file(\"atest.h5\", \"w\")\n",
    "\n",
    "# Create a NumPy array\n",
    "a = np.arange(100).reshape(20,5)\n",
    "\n",
    "# Save the array\n",
    "f.create_array(f.root, \"array1\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24],\n",
       "       [25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34],\n",
       "       [35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44],\n",
       "       [45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54],\n",
       "       [55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64],\n",
       "       [65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74],\n",
       "       [75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84],\n",
       "       [85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94],\n",
       "       [95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek data\n",
    "f.root.array1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  8,  9],\n",
       "       [22, 23, 24],\n",
       "       [37, 38, 39]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice and dice (only these slices are loaded into memory)\n",
    "ta = f.root.array1\n",
    "ta[1:10:3,2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that the read data is the same than the original\n",
    "np.allclose(ta[1:10:3,2:5], a[1:10:3,2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create another array\n",
    "ta2 = f.create_array(f.root, \"array2\", np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Gonzalo  staff  0 Oct 19 10:41 atest.h5\r\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at the size of the underlying file\n",
    "!ls -l atest.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Flush data to the file (very important to keep all your data safe!)\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Gonzalo  staff  3024 Oct 19 10:48 atest.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l atest.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()  # close access to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\r\n",
      "/array1 (Array(20, 5)) ''\r\n",
      "/array2 (Array(10,)) ''\r\n"
     ]
    }
   ],
   "source": [
    "# Look at its contents by using `ptdump` utility\n",
    "! ptdump atest.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reopen the file and revisit the datasets there\n",
    "f = tb.open_file(\"atest.h5\", mode=\"r\")  # note the 'r'ead mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=atest.h5, title='', mode='r', root_uep='/', filters=Filters(complevel=0, shuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/array1 (Array(20, 5)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/array2 (Array(10,)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the summary of the contents\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/array1 (Array(20, 5)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.root.array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24],\n",
       "       [25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34],\n",
       "       [35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44],\n",
       "       [45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54],\n",
       "       [55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64],\n",
       "       [65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74],\n",
       "       [75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84],\n",
       "       [85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94],\n",
       "       [95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.root.array1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Always close your files when you are done (or use contexts)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Create a new HDF5 file with 2 arrays on it.  One should be 2-dimensional and the other the result of summing the 2nd dimension (.sum(axis=1)).  Use contexts so that you don't have to close the file explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "import numpy as np\n",
    "\n",
    "nevt = 1000\n",
    "NROWS = 1000\n",
    "NCOLS = 100\n",
    "\n",
    "try:\n",
    "    h5f.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "h5f = tb.open_file('/Users/Gonzalo/github/Training-Next-Collaboration/data/test1.h5','w',\n",
    "                   filters=tb.Filters(complib='zlib', complevel=1))\n",
    "\n",
    "h5f.create_group(h5f.root,'DATA')\n",
    "arr2 = np.random.randint(0,high=100,size=(NROWS,NCOLS) )\n",
    "arr1 = arr2.sum(axis=1)\n",
    "\n",
    "array2 = h5f.create_array(h5f.root.DATA, \"D2\", arr2)\n",
    "array1 = h5f.create_array(h5f.root.DATA, \"D1\", arr1)\n",
    "    \n",
    "array2.flush()\n",
    "array1.flush()\n",
    "h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evt 0\n",
      "evt 100\n",
      "evt 200\n",
      "evt 300\n",
      "evt 400\n",
      "evt 500\n",
      "evt 600\n",
      "evt 700\n",
      "evt 800\n",
      "evt 900\n"
     ]
    }
   ],
   "source": [
    "import tables as tb\n",
    "import numpy as np\n",
    "\n",
    "nevt = 1000\n",
    "NROWS = 1000\n",
    "NCOLS = 100\n",
    "\n",
    "try:\n",
    "    h5f.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "h5f = tb.open_file('/Users/Gonzalo/github/Training-Next-Collaboration/data/test1.h5','w',\n",
    "                   filters=tb.Filters(complib='zlib', complevel=1))\n",
    "\n",
    "h5f.create_group(h5f.root,'DATA')\n",
    "\n",
    "array2 = h5f.create_earray(h5f.root.DATA, \"D2\",\n",
    "                           atom=tb.Int16Atom(),     #not Float32! bad for compression\n",
    "                           shape=(0, NROWS, NCOLS),\n",
    "                           expectedrows=nevt)\n",
    "\n",
    "array1 = h5f.create_earray(h5f.root.DATA, \"D1\",\n",
    "                           atom=tb.Int16Atom(),     #not Float32! bad for compression\n",
    "                           shape=(0, NROWS),\n",
    "                           expectedrows=nevt)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(nevt):\n",
    "    if not i%100:print('evt {}'.format(i))\n",
    "    numbers = np.random.randint(0,high=100,size=(NROWS,NCOLS) )\n",
    "    sumnumb = numbers.sum(axis=1)\n",
    "    array2.append( numbers.reshape(1,NROWS,NCOLS) )\n",
    "    array1.append( sumnumb.reshape(1,NROWS) )\n",
    "    \n",
    "array2.flush()\n",
    "array1.flush()\n",
    "h5f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the object tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-open the existing file in 'a'ppend mode\n",
    "f = tb.open_file(\"atest.h5\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=atest.h5, title='', mode='a', root_uep='/', filters=Filters(complevel=0, shuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/array1 (Array(20, 5)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/array2 (Array(10,)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atest.h5 (File) ''\n",
      "Last modif.: 'Wed Oct 19 10:48:42 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/array1 (Array(20, 5)) ''\n",
      "/array2 (Array(10,)) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can get a shortened view too:\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/group1 (Group) 'Title for group1'\n",
       "  children := []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new group\n",
    "f.create_group(f.root, 'group1', 'Title for group1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=atest.h5, title='', mode='a', root_uep='/', filters=Filters(complevel=0, shuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/array1 (Array(20, 5)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/array2 (Array(10,)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/group1 (Group) 'Title for group1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.move_node(f.root.array1, f.root.group1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=atest.h5, title='', mode='a', root_uep='/', filters=Filters(complevel=0, shuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/array2 (Array(10,)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/group1 (Group) 'Title for group1'\n",
       "/group1/array1 (Array(20, 5)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/g1/g2/g3/g4/g5 (Group) ''\n",
       "  children := []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a very nested group (note the `createparents` parameter)\n",
    "f.create_group('/g1/g2/g3/g4', 'g5', createparents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atest.h5 (File) ''\n",
      "Last modif.: 'Wed Oct 19 10:48:42 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/array2 (Array(10,)) ''\n",
      "/g1 (Group) ''\n",
      "/group1 (Group) 'Title for group1'\n",
      "/group1/array1 (Array(20, 5)) ''\n",
      "/g1/g2 (Group) ''\n",
      "/g1/g2/g3 (Group) ''\n",
      "/g1/g2/g3/g4 (Group) ''\n",
      "/g1/g2/g3/g4/g5 (Group) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/g1/g2/g3/g4/g5/array2 (Array(10,)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an array in the 'very nested' group\n",
    "f.create_array(f.root.g1.g2.g3.g4.g5, 'array2', np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atest.h5 (File) ''\n",
      "Last modif.: 'Wed Oct 19 10:48:42 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/array2 (Array(10,)) ''\n",
      "/g1 (Group) ''\n",
      "/group1 (Group) 'Title for group1'\n",
      "/group1/array1 (Array(20, 5)) ''\n",
      "/g1/g2 (Group) ''\n",
      "/g1/g2/g3 (Group) ''\n",
      "/g1/g2/g3/g4 (Group) ''\n",
      "/g1/g2/g3/g4/g5 (Group) ''\n",
      "/g1/g2/g3/g4/g5/array2 (Array(10,)) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing nodes is very easy\n",
    "f.remove_node(f.root.g1.g2.g3.g4.g5.array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atest.h5 (File) ''\n",
      "Last modif.: 'Wed Oct 19 11:18:12 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/array2 (Array(10,)) ''\n",
      "/g1 (Group) ''\n",
      "/group1 (Group) 'Title for group1'\n",
      "/group1/array1 (Array(20, 5)) ''\n",
      "/g1/g2 (Group) ''\n",
      "/g1/g2/g3 (Group) ''\n",
      "/g1/g2/g3/g4 (Group) ''\n",
      "/g1/g2/g3/g4/g5 (Group) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/array2 (Array(10,)) ''\n",
      "/g1 (Group) ''\n",
      "/group1 (Group) 'Title for group1'\n",
      "/g1/g2 (Group) ''\n",
      "/group1/array1 (Array(20, 5)) ''\n",
      "/g1/g2/g3 (Group) ''\n",
      "/g1/g2/g3/g4 (Group) ''\n",
      "/g1/g2/g3/g4/g5 (Group) ''\n"
     ]
    }
   ],
   "source": [
    "# Show the PyTables File object working as an iterator\n",
    "for n in f:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/array2 (Array(10,)) ''\n",
      "/g1 (Group) ''\n",
      "/group1 (Group) 'Title for group1'\n",
      "/g1/g2 (Group) ''\n",
      "/group1/array1 (Array(20, 5)) ''\n",
      "/g1/g2/g3 (Group) ''\n",
      "/g1/g2/g3/g4 (Group) ''\n",
      "/g1/g2/g3/g4/g5 (Group) ''\n"
     ]
    }
   ],
   "source": [
    "# The `File.walk_nodes` method offers more flexibility\n",
    "for n in f.walk_nodes():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group1 (Group) 'Title for group1'\n",
      "/group1/array1 (Array(20, 5)) ''\n"
     ]
    }
   ],
   "source": [
    "# Get info from a certain point of the hierarchy on\n",
    "for n in f.walk_nodes(f.root.group1):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# walknodes allows to iterate over specific classes\n",
    "for n in f.walk_nodes(f.root.group1, classname=\"Array\"):\n",
    "    print(n[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use the file that you created in the previous exercise and create a new group called 'reduced' and titled 'My Reduced data' and move the 1-dimensional array there.  Look at the final contents with the ptdump utility.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NoSuchNodeError",
     "evalue": "group ``/DATA`` does not have a child named ``D1``",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchNodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b4e887579477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'/REDUCED'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'REDUCED'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREDUCED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/tables/group.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_add_children_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmydict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f_get_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/tables/group.py\u001b[0m in \u001b[0;36m_f_get_child\u001b[0;34m(self, childname)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_check_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_check_has_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mchildpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/tables/group.py\u001b[0m in \u001b[0;36m_g_check_has_child\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise NoSuchNodeError(\n\u001b[1;32m    401\u001b[0m                 \u001b[0;34m\"group ``%s`` does not have a child named ``%s``\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 % (self._v_pathname, name))\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchNodeError\u001b[0m: group ``/DATA`` does not have a child named ``D1``"
     ]
    }
   ],
   "source": [
    "import tables as tb\n",
    "import numpy as np\n",
    "\n",
    "h5f = tb.open_file('/Users/Gonzalo/github/Training-Next-Collaboration/data/test1.h5','r+',\n",
    "                   filters=tb.Filters(complib='zlib', complevel=1))\n",
    "\n",
    "if not '/REDUCED' in h5f:\n",
    "    h5f.create_group(h5f.root,'REDUCED')\n",
    "h5f.move_node(h5f.root.DATA.D1, h5f.root.REDUCED)\n",
    "print(h5f)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-open the file\n",
    "f = tb.open_file(\"atest.h5\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atest.h5 (File) ''\n",
      "Last modif.: 'Wed Oct 19 12:20:00 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/array2 (Array(10,)) ''\n",
      "/g1 (Group) ''\n",
      "/group1 (Group) 'Title for group1'\n",
      "/group1/array1 (Array(20, 5)) ''\n",
      "/g1/g2 (Group) ''\n",
      "/g1/g2/g3 (Group) ''\n",
      "/g1/g2/g3/g4 (Group) ''\n",
      "/g1/g2/g3/g4/g5 (Group) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/array2._v_attrs (AttributeSet), 5 attributes:\n",
       "   [CLASS := 'ARRAY',\n",
       "    FLAVOR := 'numpy',\n",
       "    TITLE := '',\n",
       "    VERSION := '2.4',\n",
       "    myattr := 12.300000000000001]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the attrs in /array2\n",
    "f.root.array2.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a new attribute to /array2\n",
    "f.root.array2.attrs.myattr = \"Hello World!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/array2._v_attrs (AttributeSet), 5 attributes:\n",
       "   [CLASS := 'ARRAY',\n",
       "    FLAVOR := 'numpy',\n",
       "    TITLE := '',\n",
       "    VERSION := '2.4',\n",
       "    myattr := 'Hello World!']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.root.array2.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/array2 (Array(10,)) ''\r\n",
      "  /array2._v_attrs (AttributeSet), 5 attributes:\r\n",
      "   [CLASS := 'ARRAY',\r\n",
      "    FLAVOR := 'numpy',\r\n",
      "    TITLE := '',\r\n",
      "    VERSION := '2.4',\r\n",
      "    myattr := 12.300000000000001]\r\n"
     ]
    }
   ],
   "source": [
    "# Has the modification arrived to disk yet? \n",
    "!ptdump -a atest.h5:/array2  # note the -a flag and node specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nope, so force a flush\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/array2 (Array(10,)) ''\r\n",
      "  /array2._v_attrs (AttributeSet), 5 attributes:\r\n",
      "   [CLASS := 'ARRAY',\r\n",
      "    FLAVOR := 'numpy',\r\n",
      "    TITLE := '',\r\n",
      "    VERSION := '2.4',\r\n",
      "    myattr := 'Hello World!']\r\n"
     ]
    }
   ],
   "source": [
    "!ptdump -a atest.h5:/array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attributes can also be general arrays\n",
    "f.root.array2.attrs.myarray = np.arange(10)\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/array2 (Array(10,)) ''\r\n",
      "  /array2._v_attrs (AttributeSet), 6 attributes:\r\n",
      "   [CLASS := 'ARRAY',\r\n",
      "    FLAVOR := 'numpy',\r\n",
      "    TITLE := '',\r\n",
      "    VERSION := '2.4',\r\n",
      "    myarray := array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\r\n",
      "    myattr := 'Hello World!']\r\n"
     ]
    }
   ],
   "source": [
    "!ptdump -a atest.h5:/array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a shortcut to the attribute handler\n",
    "attrs = f.root.array2.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/array2._v_attrs (AttributeSet), 6 attributes:\n",
       "   [CLASS := 'ARRAY',\n",
       "    FLAVOR := 'numpy',\n",
       "    TITLE := '',\n",
       "    VERSION := '2.4',\n",
       "    myarray := array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "    myattr := 'Hello World!']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/array2._v_attrs (AttributeSet), 5 attributes:\n",
       "   [CLASS := 'ARRAY',\n",
       "    FLAVOR := 'numpy',\n",
       "    TITLE := '',\n",
       "    VERSION := '2.4',\n",
       "    myattr := 'Hello World!']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing an attribute\n",
    "del attrs.myarray\n",
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/array2._v_attrs (AttributeSet), 5 attributes:\n",
       "   [CLASS := 'ARRAY',\n",
       "    FLAVOR := 'numpy',\n",
       "    TITLE := '',\n",
       "    VERSION := '2.4',\n",
       "    myattr := 12.300000000000001]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overwrite an existing one (be careful with this feature!)\n",
    "attrs.myattr = 12.3\n",
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group1/array1._v_attrs (AttributeSet), 4 attributes:\n",
      "   [CLASS := 'ARRAY',\n",
      "    FLAVOR := 'numpy',\n",
      "    TITLE := '',\n",
      "    VERSION := '2.4']\n"
     ]
    }
   ],
   "source": [
    "# Print the attributes for all the arrays in the object tree\n",
    "for n in f.walk_nodes(f.root.group1, classname=\"Array\"):\n",
    "    print(repr(n.attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use the file in the previous exercise and add an attribute to the 1-dimensional array specifying the mean and the standard deviation. Use ptdump -a to check that the attributes are there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/REDUCED/D1._v_attrs (AttributeSet), 6 attributes:\n",
      "   [CLASS := 'ARRAY',\n",
      "    FLAVOR := 'numpy',\n",
      "    TITLE := '',\n",
      "    VERSION := '2.4',\n",
      "    mean := 4941.3069999999998,\n",
      "    stddev := 291.55082704564569]\n",
      "/REDUCED/D1 (Array(1000,)) ''\n",
      "  /REDUCED/D1._v_attrs (AttributeSet), 6 attributes:\n",
      "   [CLASS := 'ARRAY',\n",
      "    FLAVOR := 'numpy',\n",
      "    TITLE := '',\n",
      "    VERSION := '2.4',\n",
      "    mean := 4941.3069999999998,\n",
      "    stddev := 291.55082704564569]\n"
     ]
    }
   ],
   "source": [
    "h5f = tb.open_file('/Users/Gonzalo/github/Training-Next-Collaboration/data/test1.h5','r+')\n",
    "\n",
    "array = h5f.root.REDUCED.D1\n",
    "array.attrs.mean = np.mean(array)\n",
    "array.attrs.stddev = np.std(array)\n",
    "array.flush()\n",
    "print(repr(array.attrs))\n",
    "h5f.close()\n",
    "\n",
    "! ptdump -a /Users/Gonzalo/github/Training-Next-Collaboration/data/test1.h5:/REDUCED/D1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunked datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = tb.open_file('ctest.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/carray (CArray(10000, 1000)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (16, 1000)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an un-initialized CArray (Compressible Array)\n",
    "f.create_carray(f.root, 'carray', tb.Float64Atom(), (10000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Flush everything to disk\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Gonzalo  staff   1.7K Oct 19 12:31 ctest.h5\r\n"
     ]
    }
   ],
   "source": [
    "# The container is there, but not the data (yet)\n",
    "!ls -lh ctest.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 ms, sys: 67.6 ms, total: 92.8 ms\n",
      "Wall time: 182 ms\n"
     ]
    }
   ],
   "source": [
    "# Push some data into this carray container\n",
    "ca = f.root.carray\n",
    "na = np.linspace(0, 1, 1e7).reshape(10000,1000)\n",
    "%time ca[:] = na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Flush (we can specify which node should be flushed)\n",
    "ca.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Gonzalo  staff    76M Oct 19 12:31 ctest.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ctest.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.2939453125"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(ca.shape) * ca.dtype.itemsize / 2**20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   2.00000020e-07,   4.00000040e-07, ...,\n",
       "          9.94000099e-05,   9.96000100e-05,   9.98000100e-05],\n",
       "       [  1.00000010e-04,   1.00200010e-04,   1.00400010e-04, ...,\n",
       "          1.99400020e-04,   1.99600020e-04,   1.99800020e-04],\n",
       "       [  2.00000020e-04,   2.00200020e-04,   2.00400020e-04, ...,\n",
       "          2.99400030e-04,   2.99600030e-04,   2.99800030e-04],\n",
       "       ..., \n",
       "       [  7.00000070e-04,   7.00200070e-04,   7.00400070e-04, ...,\n",
       "          7.99400080e-04,   7.99600080e-04,   7.99800080e-04],\n",
       "       [  8.00000080e-04,   8.00200080e-04,   8.00400080e-04, ...,\n",
       "          8.99400090e-04,   8.99600090e-04,   8.99800090e-04],\n",
       "       [  9.00000090e-04,   9.00200090e-04,   9.00400090e-04, ...,\n",
       "          9.99400100e-04,   9.99600100e-04,   9.99800100e-04]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve only part of the data\n",
    "ca[:10,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using compression with chunked arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = tb.open_file('ctest-zlib.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a CArray (Compressible Array) using the zlib compressor\n",
    "filters = tb.Filters(complib='zlib', complevel=1)\n",
    "ca = f.create_carray(f.root, 'carray', tb.Float64Atom(), (10000,1000),\n",
    "                     filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 417 ms, sys: 21.9 ms, total: 439 ms\n",
      "Wall time: 457 ms\n"
     ]
    }
   ],
   "source": [
    "# Push some data on this carray container\n",
    "na = np.linspace(0, 1, 1e7).reshape(10000,1000)\n",
    "%time ca[:] = na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Gonzalo  staff   6.7M Oct 19 12:54 ctest-zlib.h5\r\n"
     ]
    }
   ],
   "source": [
    "# Flush the carray container only\n",
    "ca.flush()\n",
    "!ls -lh ctest-zlib.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.2939453125"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(ca.shape) * ca.dtype.itemsize / 2**20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened \"ctest-zlib.h5\" with sec2 driver.\r\n",
      "carray                   Dataset {10000/10000, 1000/1000}\r\n",
      "    Attribute: CLASS scalar\r\n",
      "        Type:      6-byte null-terminated ASCII string\r\n",
      "        Data:  \"CARRAY\"\r\n",
      "    Attribute: TITLE null\r\n",
      "        Type:      1-byte null-terminated ASCII string\r\n",
      "\r\n",
      "    Attribute: VERSION scalar\r\n",
      "        Type:      3-byte null-terminated ASCII string\r\n",
      "        Data:  \"1.1\"\r\n",
      "    Location:  1:1024\r\n",
      "    Links:     1\r\n",
      "    Chunks:    {16, 1000} 128000 bytes\r\n",
      "    Storage:   80000000 logical bytes, 7004415 allocated bytes, 1142.14% utilization\r\n",
      "    Filter-0:  shuffle-2 OPT {8}\r\n",
      "    Filter-1:  deflate-1 OPT {1}\r\n",
      "    Type:      native double\r\n",
      "H5tools-DIAG: Error detected in HDF5:tools (1.8.17) thread 140735105355776:\r\n",
      "  #000: h5tools_dump.c line 1836 in h5tools_dump_mem(): H5Sis_simple failed\r\n",
      "    major: Failure in tools library\r\n",
      "    minor: error in function\r\n"
     ]
    }
   ],
   "source": [
    "# Look at the file with a native HDF5 tool\n",
    "!h5ls -v ctest-zlib.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using compression (Blosc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = tb.open_file('ctest-blosc.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a CArray (Compressible Array) using the Blosc compressor\n",
    "filters = tb.Filters(complib='blosc:lz4', complevel=9)\n",
    "ca = f.create_carray(f.root, 'carray', tb.Float64Atom(), (10000,1000),\n",
    "                     filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.6 ms, sys: 14.8 ms, total: 104 ms\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "# Push some data on this carray container\n",
    "na = np.linspace(0, 1, 1e7).reshape(10000,1000)\n",
    "%time ca[:] = na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note how witing a compressed carray is faster in the this case than both the uncompressed case above (~500 ms) and with using zlib (~750 ms).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Gonzalo  staff   7.7M Oct 19 12:58 ctest-blosc.h5\r\n"
     ]
    }
   ],
   "source": [
    "f.close()\n",
    "!ls -lh ctest-blosc.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you see, the compression ratio is quite the same than with zlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "PyTables comes with support for different compressors, namely 'zlib' (the default), 'bzip2' and 'blosc:X' where X is a codec can be one of 'blosclz', 'lz4', 'lz4hc', 'snappy', 'zlib' (and 'zstd' from PyTables 3.3 on).  Based on the example above, do a small study on which ones work best.\n",
    "\n",
    "* Which one compresses best?\n",
    "* Which one compresses faster?\n",
    "* Which one shows the best balance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying chunk size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a chunked dataset, a chunksize is chosen automatically based on some heuristics.  However, you may want to specify your own chunksize and see the best for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "na = np.linspace(0, 1, 1e7).reshape(10000,1000)\n",
    "for nrows in range(10, 210, 30):\n",
    "    with tb.open_file(\"chunk_study.h5\", \"w\") as f:\n",
    "        chunkshape = (nrows, 1000)\n",
    "        print(\"chunkshape:\", chunkshape)\n",
    "        filters = tb.Filters(complib=\"blosc:lz4\", complevel=9)\n",
    "        ca = f.create_carray(f.root, 'carray', tb.Float64Atom(), (10000,1000),\n",
    "                            filters=filters, chunkshape=chunkshape)\n",
    "        %time ca[:] = na\n",
    "    !ls -lh chunk_study.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ptrepack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the 'ptrepack' utility to copy HDF5 whole files (or only parts) and change different parameters during the copy process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ptrepack -o --complib zlib --complevel 1 ctest.h5 ctest-repacked-zlib.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ptrepack -o --complib blosc:lz4 --complevel 9 ctest.h5 ctest-repacked-blosc.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ptrepack -o --complib blosc:lz4 --complevel 9 --chunkshape '(1000,1000)' ctest.h5 ctest-repacked-blosc-chunkshape.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries in Table objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The description for the tabular data\n",
    "class TabularData(tb.IsDescription):\n",
    "    col1 = tb.StringCol(200)\n",
    "    col2 = tb.IntCol()\n",
    "    col3 = tb.FloatCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open a file and create the Table container\n",
    "f = tb.open_file('atable.h5', 'w')\n",
    "t = f.create_table(f.root, 'table', TabularData, 'table title',\n",
    "                   filters=tb.Filters(9, 'blosc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#  Fill the table with some 1 million rows\n",
    "r = t.row\n",
    "for i in range(1000*1000):\n",
    "    r['col1'] = str(i)\n",
    "    r['col2'] = i + 1\n",
    "    r['col3'] = i * (i + 1)\n",
    "    r.append()\n",
    "t.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Size on disk\n",
    "!ls -lh atable.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Real size\n",
    "np.prod(t.shape) * t.dtype.itemsize / 2**20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do a query (regular)\n",
    "%time [r['col1'] for r in t if r['col2'] < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Repeat the query, but using in-kernel method\n",
    "%time [r['col1'] for r in t.where('col2 < 5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Performing complex conditions (regular query)\n",
    "%time [r['col1'] for r in t if r['col2'] < 5 and r['col3'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complex, in-kernel queries\n",
    "%time [r['col1'] for r in t.where('(col2 < 5) & (col3 < 10)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a structured array out of disk\n",
    "sa = t[:]\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform the query in-memory using pure NumPy machinery \n",
    "%time sa[((sa['col2'] < 5) & (sa['col3'] < 10))]['col1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an index for the on-disk table\n",
    "%time t.cols.col2.create_csindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Repeat the complex query (indexed)\n",
    "%time [r['col1'] for r in t.where('(col2 < 5) & (col3 < 10)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing normally offers the best speed for doing queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the 'ic_dst...' file in the data/ directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = tb.open_file(\"../data/ic_dst_NEXT_v0_08_02_Kr_ACTIVE_0_0_5bar_MCRD_10000.root.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Determine the chunksize of the /MLR/mau and /RD/pmtrwf datasets\n",
    "\n",
    "* Copy them to another (new) HDF5 file using different chunksizes and compressors.  Determine the ones that offers best ratio and speed. (use ptrepack).\n",
    "\n",
    "* Use the /TWF/TWF and /Sensors/DataSiPM and do some small analysis (e.g. plotting the times for TWF, or query them based on some conditions that make sense)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
